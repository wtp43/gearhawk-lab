apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: infra-cluster
  namespace: cnpg-database
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  imageName: ghcr.io/cloudnative-pg/postgresql:17.5
  imagePullPolicy: IfNotPresent
  instances: 2
  startDelay: 300
  stopDelay: 300
  primaryUpdateStrategy: unsupervised

  postgresql:
    parameters:
      timezone: "Canada/Eastern"
      max_connections: "200"
      shared_buffers: "512MB"
      effective_cache_size: "1536MB"
      maintenance_work_mem: "128MB"
      checkpoint_completion_target: "0.9"
      wal_buffers: "16MB"
      default_statistics_target: "100"
      random_page_cost: "1.1"
      effective_io_concurrency: "200"
      work_mem: "2520kB"
      huge_pages: "off"
      min_wal_size: "1GB"
      max_wal_size: "4GB"

    pg_hba:
      - host all all all md5

  bootstrap:
    # initdb:
    #   database: app
    #   owner: app
    #   secret:
    #     name: gearhawk-postgres-app
    recovery:
      source: s3
      database: postgres
      owner: app
      secret:
        name: gearhawk-postgres-app

  enableSuperuserAccess: true
  superuserSecret:
    name: gearhawk-postgres-superuser

  storage:
    # TODO: benchmark and use local storage
    storageClass: longhorn
    size: 10Gi

  externalClusters:
    - name: s3
      plugin:
        name: barman-cloud.cloudnative-pg.io
        parameters:
          # Recovery Object Store (pull, read-only)
          barmanObjectName: s3-store
          serverName: recovery-target-infra # the target path where base + wal objects are stored
  managed:
    roles:
      - name: gearhawk-pipeline-worker
        ensure: present
        login: true
        superuser: false
        createdb: true
        createrole: false
        inherit: false
        replication: false
        bypassrls: false
        passwordSecret:
          name: gearhawk-pipeline-worker
  plugins:
    - name: barman-cloud.cloudnative-pg.io
      isWALArchiver: true
      parameters:
        # Backup Object Store (push, read-write)
        barmanObjectName: s3-store
        serverName: scheduled-backup-infra # this s3 path must be empty during recovery
  resources:
    requests:
      memory: "1Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "4"
  monitoring:
    enablePodMonitor: true

  nodeMaintenanceWindow:
    inProgress: false
    reusePVC: false
