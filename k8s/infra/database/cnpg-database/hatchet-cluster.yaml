apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: hatchet-pg-cluster
  namespace: cnpg-database
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  imageName: ghcr.io/cloudnative-pg/postgresql:17.5
  imagePullPolicy: IfNotPresent
  instances: 3
  startDelay: 300
  stopDelay: 300
  primaryUpdateStrategy: unsupervised

  postgresql:
    # TODO: performance tuning https://www.enterprisedb.com/postgres-tutorials/introduction-postgresql-performance-tuning-and-optimization?lang=en
    # using: https://pgtune.leopard.in.ua/
    # WARNING: WAL tuning parameters should be the same as the backups
    parameters:
      timezone: "Etc/UTC"
      max_connections: "100"
      shared_buffers: "1536MB"
      effective_cache_size: "4608MB"
      maintenance_work_mem: "384MB"
      checkpoint_completion_target: "0.9"
      wal_buffers: "16MB"
      default_statistics_target: "100"
      random_page_cost: "1.1"
      effective_io_concurrency: "200"
      work_mem: "14563kB"
      huge_pages: "off"
      min_wal_size: "1GB"
      max_wal_size: "4GB"
    pg_hba:
      # - host all all 10.244.0.0/16 md5
      - host all all all md5

  bootstrap:
    initdb:
      database: hatchet
      owner: hatchet
      secret:
        name: hatchet-user
    # recovery:
    #   source: s3
    #   database: postgres
    #   owner: app
    #   secret:
    #     name: gearhawk-postgres-app

  enableSuperuserAccess: true
  superuserSecret:
    name: gearhawk-postgres-superuser

  storage:
    # TODO: benchmark and use local storage
    storageClass: no-replicas
    size: 15Gi

  # externalClusters:
  #   - name: s3
  #     plugin:
  #       name: barman-cloud.cloudnative-pg.io
  #       parameters:
  #         # Recovery Object Store (pull, read-only)
  #         barmanObjectName: s3-store
  #         serverName: recovery-target # the target path where base + wal objects are stored
  # plugins:
  #   - name: barman-cloud.cloudnative-pg.io
  #     isWALArchiver: true
  #     parameters:
  #       # Backup Object Store (push, read-write)
  #       barmanObjectName: s3-store
  #       serverName: scheduled-backup # this s3 path must be empty during recovery

  resources:
    requests:
      memory: "4Gi"
      cpu: "2"
    limits:
      memory: "4Gi"
      cpu: "4"
  monitoring:
    enablePodMonitor: true
  affinity:
    enablePodAntiAffinity: true

  nodeMaintenanceWindow:
    inProgress: false
    reusePVC: false
